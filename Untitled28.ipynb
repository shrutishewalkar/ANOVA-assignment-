{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5eb1d29f-fa8b-4199-874d-9ae2b5149edb",
   "metadata": {},
   "source": [
    "Q1. Explain the assumptions required to use ANOVA and provide examples of violations that could impact the validity of the results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee723522-849f-473e-9c86-798cf3eecc21",
   "metadata": {},
   "source": [
    "Assumptions of ANOVA:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00045a6a-4564-4f63-be1b-5b2b66cc7045",
   "metadata": {},
   "source": [
    "1. Normality: The data should be normally distributed in each group. Violations of this assumption can occur when the data is skewed, has extreme outliers, or is bimodal.\n",
    "\n",
    "2. Homogeneity of variance: The variance within each group should be approximately equal. This assumption is also known as the assumption of homoscedasticity. Violations of this assumption can occur when the variance in one group is much larger than the variance in another group.\n",
    "\n",
    "3. Independence: The observations should be independent of each other. Violations of this assumption can occur when there are dependencies between observations, such as when repeated measurements are taken on the same individual."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36763b91-ec6b-4089-acbe-5896521f8506",
   "metadata": {},
   "source": [
    "Violations that could impact the validity of the results:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8207ad71-aa56-487f-89df-5c7a346f295b",
   "metadata": {},
   "source": [
    "1. Non-normality: If the data is not normally distributed in each group, the results of the ANOVA may not be reliable. For example, if the data is skewed, a transformation of the data or a non-parametric test may be necessary.\n",
    "\n",
    "2. Heteroscedasticity: If the variance within each group is not approximately equal, the results of the ANOVA may be biased. For example, if the variance in one group is much larger than the variance in another group, the results may be driven by the group with the larger variance.\n",
    "\n",
    "3. Dependence: If the observations are not independent of each other, the results of the ANOVA may be unreliable. For example, if repeated measurements are taken on the same individual, the observations within each group may be more similar than the observations between groups, leading to an overestimate of the differences between groups."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "865b3382-f985-4936-adf4-acbe1b598ba4",
   "metadata": {},
   "source": [
    "Q2. What are the three types of ANOVA, and in what situations would each be used?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce20c3a3-dd34-47f0-a4c7-9b4c4da1d03b",
   "metadata": {},
   "source": [
    "There are three main types of ANOVA:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7725b7d-7ac2-497d-9ebc-8c092393f464",
   "metadata": {},
   "source": [
    "1. One-way ANOVA: One-way ANOVA is used when there is one independent variable (also called a factor) with three or more levels or groups, and the dependent variable is continuous. It is used to test whether there are any significant differences in the means of the dependent variable across the different levels or groups of the independent variable. For example, a one-way ANOVA could be used to test whether there are any differences in the mean weight of people across three different diet plans.\n",
    "\n",
    "2. Two-way ANOVA: Two-way ANOVA is used when there are two independent variables (also called factors), and the dependent variable is continuous. It is used to test for main effects of each independent variable, as well as any interaction effects between the independent variables. For example, a two-way ANOVA could be used to test whether there are any differences in the mean weight of people across three different diet plans and two different exercise routines.\n",
    "\n",
    "3. Repeated measures ANOVA: Repeated measures ANOVA is used when the dependent variable is measured on the same subjects at different time points, or under different conditions. It is used to test whether there are any significant differences in the means of the dependent variable across the different time points or conditions. For example, a repeated measures ANOVA could be used to test whether there are any differences in the mean anxiety levels of participants before and after a stress-inducing task."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76399bfd-e4e7-4d32-b024-d1cb6ba52fae",
   "metadata": {},
   "source": [
    "Q3. What is the partitioning of variance in ANOVA, and why is it important to understand this concept?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a739ce12-71bc-45fa-89ed-2e4a9389b306",
   "metadata": {},
   "source": [
    "Partitioning of variance in ANOVA refers to the process of dividing the total variation in a dependent variable into different sources of variation. The goal of ANOVA is to determine whether there are significant differences in means between groups or conditions, and partitioning of variance helps to identify the sources of variation that contribute to these differences.\n",
    "\n",
    "In ANOVA, the total variation in the dependent variable is partitioned into two types of variation:\n",
    "\n",
    "Between-group variation\n",
    "Within-group variation\n",
    "By partitioning the variation in this way, ANOVA can test whether the between-group variation is significantly greater than the within-group variation, which would indicate that the groups or conditions being compared are significantly different."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e74805a8-51e4-4446-87b8-8a7a0de16af2",
   "metadata": {},
   "source": [
    "Understanding partitioning of variance is important because it allows researchers to determine which sources of variation are most important in explaining the differences in means between groups or conditions. This can help to identify factors that are driving the observed differences and can inform further research or intervention efforts. Additionally, partitioning of variance can help to identify any sources of error or variability in the data, which can improve the reliability and validity of the results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dd01523-e689-468f-a2fe-3d370765f399",
   "metadata": {},
   "source": [
    "Q4. How would you calculate the total sum of squares (SST), explained sum of squares (SSE), and residual sum of squares (SSR) in a one-way ANOVA using Python?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2a9a8d6-e3c3-486e-ac5f-fd96dba44c15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SST: 442.20027347393636\n",
      "SSE: 29.999927882554044\n",
      "SSR: 412.2003455913823\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "\n",
    "#generate random data\n",
    "np.random.seed(123)\n",
    "data = pd.DataFrame({'group': np.random.choice(['A', 'B', 'C'], size=90),\n",
    "                     'value': np.random.normal(loc=10, scale=2, size=90)})\n",
    "\n",
    "group_means = data.groupby('group')['value'].mean()\n",
    "grand_mean = data['value'].mean()\n",
    "SST = ((data['value'] - grand_mean) ** 2).sum()\n",
    "SSE = ((group_means - grand_mean) ** 2 * data['group'].value_counts()).sum()\n",
    "SSR = SST - SSE\n",
    "\n",
    "print(\"SST:\", SST)\n",
    "print(\"SSE:\", SSE)\n",
    "print(\"SSR:\", SSR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93ceed43-bc63-4795-9dd8-6e6e6bc000a9",
   "metadata": {},
   "source": [
    "Q5. In a two-way ANOVA, how would you calculate the main effects and interaction effects using Python?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3dfc87bb-450b-4b23-90b4-d332f7e84fb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Main Effects:\n",
      "     sum_sq   df         F\n",
      "A  0.971609  1.0  0.666667\n",
      "B  0.971609  1.0  0.666667\n",
      "\n",
      "Interaction Effect:\n",
      "sum_sq    0.804310\n",
      "df        1.000000\n",
      "F         0.551875\n",
      "Name: A:B, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "np.random.seed(123)\n",
    "df = pd.DataFrame({'A': np.repeat(['a', 'b'], 25),\n",
    "                   'B': np.repeat(['x', 'y'], 25),\n",
    "                   'score': np.random.normal(0, 1, 50)})\n",
    "\n",
    "model = ols('score ~ A + B + A:B', data=df).fit()\n",
    "anova_table = sm.stats.anova_lm(model, typ=2)\n",
    "\n",
    "main_effects = anova_table[['sum_sq', 'df', 'F']].iloc[:2]\n",
    "interaction_effect = anova_table[['sum_sq', 'df', 'F']].iloc[2]\n",
    "\n",
    "print('Main Effects:')\n",
    "print(main_effects)\n",
    "print('\\nInteraction Effect:')\n",
    "print(interaction_effect)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5daecd0-739e-4447-8351-7fccc9a5b021",
   "metadata": {},
   "source": [
    "Q6. Suppose you conducted a one-way ANOVA and obtained an F-statistic of 5.23 and a p-value of 0.02. What can you conclude about the differences between the groups, and how would you interpret these results?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78e734fe-ea49-443f-a271-278d11fa346b",
   "metadata": {},
   "source": [
    "If a one-way ANOVA yields an F-statistic of 5.23 and a p-value of 0.02, it means that there is evidence of a significant difference between the groups. Specifically, it means that the variance between the groups is greater than the variance within the groups, which suggests that there are significant differences in the means of the groups and we can conclude that at least one group has a mean that is significantly different from the others.\n",
    "\n",
    "However, we cannot determine which specific groups are different from each other based solely on the ANOVA results. Further analysis, such as post-hoc tests or confidence intervals, may be needed to determine the nature of the differences between the groups."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42343dea-dd19-44ca-9e89-f152f10953d4",
   "metadata": {},
   "source": [
    "Q7. In a repeated measures ANOVA, how would you handle missing data, and what are the potential consequences of using different methods to handle missing data?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a73865df-7e50-4383-98d3-b5e68b4bd6e3",
   "metadata": {},
   "source": [
    "Handling missing data in a repeated measures ANOVA can be challenging, as the repeated nature of the design means that missing data can have a more profound impact on the analysis than in other designs. There are several methods for handling missing data in a repeated measures ANOVA, including:\n",
    "\n",
    "Pairwise deletion: This method involves omitting any cases with missing data for a particular variable, only using cases that have complete data for that variable. This method is easy to implement, but it can result in a loss of statistical power and can produce biased estimates if the missing data is not missing completely at random.\n",
    "\n",
    "Listwise deletion: This method involves omitting any cases that have missing data for any of the variables included in the analysis. This method avoids the potential bias of pairwise deletion, but it can also lead to a loss of statistical power if a substantial portion of the data is missing.\n",
    "\n",
    "Imputation: This method involves replacing missing data with estimated values based on the available data. There are several imputation methods, including mean imputation, regression imputation, and multiple imputation. Imputation can be a useful method for reducing the impact of missing data, but it can also introduce bias if the imputation model is misspecified."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecf4ac62-19a6-4d7c-a96e-9fbee189b31d",
   "metadata": {},
   "source": [
    "Q8. What are some common post-hoc tests used after ANOVA, and when would you use each one? Provide an example of a situation where a post-hoc test might be necessary."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e56cb3b-200c-4318-bd38-d7b7fdabc116",
   "metadata": {},
   "source": [
    "Some common post-hoc tests include:\n",
    "\n",
    "1. Tukey's HSD (honestly significant difference): This test compares all possible pairs of means and controls the family-wise error rate, making it a good choice for situations where multiple comparisons are being made.\n",
    "\n",
    "2. Bonferroni correction: This test is a more conservative alternative to Tukey's HSD and adjusts the alpha level for each comparison. It is a good choice when making a small number of comparisons.\n",
    "\n",
    "3. scheffe's test: This test is a conservative test that can be used when the sample sizes are unequal, and there are more than two groups.\n",
    "\n",
    "4. Dunnett's test: This test is used when there is a control group and the other groups are being compared to the control.\n",
    "\n",
    "5. Games-Howell test: This test is used when the assumption of equal variances across groups is not met.\n",
    "\n",
    "A situation where a post-hoc test might be necessary is if an ANOVA indicates a significant difference between at least two groups, but it is unclear which specific groups are different from each other. For example, a researcher might conduct an ANOVA to compare the mean scores of three different treatment groups on a measure of anxiety. If the ANOVA shows a significant difference between the groups, a post-hoc test such as Tukey's HSD or Bonferroni correction can be used to determine which specific groups differ from each other in terms of their anxiety scores."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e752e45-206f-45f7-a8c8-91b9cffb2f90",
   "metadata": {},
   "source": [
    "Q9. A researcher wants to compare the mean weight loss of three diets: A, B, and C. They collect data from 50 participants who were randomly assigned to one of the diets. Conduct a one-way ANOVA using Python to determine if there are any significant differences between the mean weight loss of the three diets. Report the F-statistic and p-value, and interpret the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "70165734-1f7b-4df7-b4a3-dd014c7a1013",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-statistic: 9.14\n",
      "p-value: 0.0002\n",
      "There is a significant difference between the mean weight loss of the three diets.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "#generate weight loss data for three diets\n",
    "np.random.seed(123)\n",
    "diet_a = np.random.normal(loc=5.5, scale=1.5, size=50)\n",
    "diet_b = np.random.normal(loc=4.8, scale=1.2, size=50)\n",
    "diet_c = np.random.normal(loc=4.2, scale=1.0, size=50)\n",
    "\n",
    "weight_loss = np.concatenate([diet_a, diet_b, diet_c])\n",
    "group_labels = ['A'] * 50 + ['B'] * 50 + ['C'] * 50\n",
    "\n",
    "#conduct one-way ANOVA\n",
    "f_statistic, p_value = stats.f_oneway(diet_a, diet_b, diet_c)\n",
    "\n",
    "print(\"F-statistic: {:.2f}\".format(f_statistic))\n",
    "print(\"p-value: {:.4f}\".format(p_value))\n",
    "\n",
    "if p_value < 0.05:\n",
    "    print(\"There is a significant difference between the mean weight loss of the three diets.\")\n",
    "else:\n",
    "    print(\"There is no significant difference between the mean weight loss of the three diets.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbc43d31-2976-4deb-86b2-ebdfe4bb4fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q10. A company wants to know if there are any significant differences in the average time it takes to complete a task using three different software programs: Program A, Program B, and Program C. They randomly assign 30 employees to one of the programs and record the time it takes each employee to complete the task. Conduct a two-way ANOVA using Python to determine if there are any main effects or interaction effects between the software programs and employee experience level (novice vs. experienced). Report the F-statistics and p-values, and interpret the results."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
